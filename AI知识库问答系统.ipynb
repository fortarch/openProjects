{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab85de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/administrator/miniconda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:9898\n",
      " * Running on http://10.170.0.87:9898\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [12/Jun/2023 14:27:13] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Jun/2023 14:27:13] \"\u001b[36mGET /static/bot.png HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [12/Jun/2023 14:27:18] \"\u001b[36mGET /static/user.png HTTP/1.1\u001b[0m\" 304 -\n",
      "/var/folders/vd/xkclsdf95bld4btqnx9lbx280000gn/T/ipykernel_8712/1708069079.py:49: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  res = es.search(index='cupdkb_index', body=query)\n",
      "127.0.0.1 - - [12/Jun/2023 14:28:01] \"POST /api/get_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------es_results: Found-------------\n",
      "{'status': 'found', 'answers': [{'id': 'HRFmVogBgn8Xb9O1P0Gn', 'caption': 'IC卡降级交易管控', 'answer': '降级交易管控需要,可以在ICMS系统PRMCE画面可以通过“禁止银联行内IC卡境内降级的交易(POS)”、“禁止银行境内IC产品境内的降片降价交易”(ATM)”的勾选对磁条芯片复合卡进行降一级交易的禁止。'}, {'id': 'KhFmVogBgn8Xb9O1Qkhc', 'caption': 'ICMS2:修改PRMCE画面降级交易开关字段名称（服务台变更单：CHG-140708-0023）', 'answer': '标题:ICMS2:修改PRMCE画面降级交易开关字段名称 描述:PRMC画面原字符串名:禁止银联IC卡降级的交易(POS) 和 禁止银行级IC产品降度的交易'}, {'id': 'fxFmVogBgn8Xb9O1Qkdc', 'caption': 'IC卡降级交易银行级开关（服务台变更单：CHG-140618-0029）', 'answer': '标题:IC卡降级交易银行级开关 描述:根据人民银行的要求,发卡行需要在8月31日前关闭ATM、POS渠道的ICcard降级的交易,卡系统目前已经有卡片级的ICCard降一级交易开关,还有高风险地区降级别的管控。'}]}\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, MT5ForConditionalGeneration\n",
    "from elasticsearch import Elasticsearch\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.nn.functional import softmax\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "#启动docker里的elasticsearch870容器\n",
    "\n",
    "es = Elasticsearch(hosts=\"http://localhost:9200\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/administrator/nlpmodels/huggingface-T5QA\")\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"/Users/administrator/nlpmodels/huggingface-T5QA\")\n",
    "\n",
    "def get_response(input_text):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": input_text,\n",
    "                            \"fields\": [\"content\", \"caption\"],\n",
    "                            \"boost\": 2.0,\n",
    "                            \"fuzziness\": \"AUTO\",\n",
    "                            \"analyzer\": \"custom_analyzer\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"match_phrase_prefix\": {\n",
    "                            \"content\": {\n",
    "                                \"query\": input_text,\n",
    "                                \"boost\": 1.5,\n",
    "                                \"analyzer\": \"custom_analyzer\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        },\n",
    "        \"size\": 10,\n",
    "        \"_source\": [\"id\", \"caption\", \"content\"],\n",
    "        \"highlight\": {\n",
    "            \"fields\": {\n",
    "                \"content\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = es.search(index='cupdkb_index', body=query)\n",
    "    es_results = []\n",
    "    for hit in res['hits']['hits']:\n",
    "        source = hit[\"_source\"]\n",
    "        document_id = hit[\"_id\"]\n",
    "        document_caption = source[\"caption\"].replace(\"\\n\", \"\")\n",
    "        highlight = hit.get(\"highlight\", {})\n",
    "        content_highlight = highlight.get(\"content\", [])\n",
    "        content_snippet = content_highlight[0] if content_highlight else source[\"content\"]\n",
    "        content_snippet = BeautifulSoup(content_snippet, \"html.parser\").get_text()\n",
    "        \n",
    "        \n",
    "        es_results.append({\n",
    "            \"id\": document_id,\n",
    "            \"caption\": document_caption,\n",
    "            \"content\": content_snippet\n",
    "        })\n",
    "\n",
    "    answers = []\n",
    "\n",
    "    if es_results:\n",
    "        for es_result in es_results:\n",
    "            task_specific_input = f\"question: {input_text} context: {es_result['content']}\"\n",
    "            inputs = tokenizer.encode_plus(task_specific_input, return_tensors='pt')\n",
    "            outputs = model.generate(inputs['input_ids'], max_length=512, temperature=0.7, no_repeat_ngram_size=2, return_dict_in_generate=True, output_scores=True)\n",
    "            decoded_output = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "            answer = decoded_output.split('<eos>')[0]\n",
    "            scores = outputs.scores[0]\n",
    "            probabilities = softmax(scores, dim=-1)\n",
    "            avg_probability = probabilities.mean().item()\n",
    "            answers.append({\"id\": es_result[\"id\"], \"caption\": es_result[\"caption\"], \"answer\": answer, \"probability\": avg_probability})\n",
    "\n",
    "        answers.sort(key=lambda x: x['probability'], reverse=True)\n",
    "        top_answers = answers[:3]\n",
    "        \n",
    "        ###############################\n",
    "        print('----------es_results: Found-------------')\n",
    "        print({\n",
    "            'status': 'found',\n",
    "            'answers': [{'id': answer['id'], 'caption': answer['caption'], 'answer': answer['answer']} for answer in top_answers]\n",
    "        })\n",
    "        ###############################\n",
    "        \n",
    "        return {\n",
    "            'status': 'found',\n",
    "            'answers': [{'id': answer['id'], 'caption': answer['caption'], 'answer': answer['answer']} for answer in top_answers]\n",
    "        }\n",
    "    else:\n",
    "        inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
    "        outputs = model.generate(inputs, max_length=512, num_return_sequences=1, temperature=0.7, no_repeat_ngram_size=2)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        ###############################\n",
    "        print('----------es_results: Not Found-------------')\n",
    "        print({\n",
    "            'status': 'not_found',\n",
    "            'response': response\n",
    "        })\n",
    "        ###############################\n",
    "        \n",
    "        return {\n",
    "            'status': 'not_found',\n",
    "            'response': response\n",
    "        }\n",
    "    \n",
    "    \n",
    "    print('----------es_results: Error-------------')\n",
    "    print({\n",
    "        'status': 'error',\n",
    "        'message': 'Unexpected error occurred.'\n",
    "    })\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'status': 'error',\n",
    "        'message': 'Unexpected error occurred.'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/api/get_response', methods=['POST'])\n",
    "def get_flask_response():\n",
    "    data = request.get_json()\n",
    "    user_input = data['input_text']\n",
    "    try:\n",
    "        response = get_response(user_input)\n",
    "        return jsonify(response)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return jsonify({\"status\": \"error\", \"message\": \"Unexpected error occurred.\"})\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "@app.route('/api/get_detail', methods=['POST'])\n",
    "def get_detail():\n",
    "    data = request.get_json()\n",
    "    id = data['id']\n",
    "    # 根据ID获取详细内容\n",
    "    detail = get_detail_content(id)  # 自定义函数，根据ID获取详细内容\n",
    "    \n",
    "    if detail:\n",
    "        return jsonify({'status': 'found', 'detail': detail})\n",
    "    else:\n",
    "        return jsonify({'status': 'not_found'})\n",
    "\n",
    "\n",
    "@app.route('/detail')\n",
    "def show_detail():\n",
    "    id = request.args.get('id')\n",
    "    detail = get_detail_content(id)  # 自定义函数，根据ID获取详细内容\n",
    "    \n",
    "    if detail:\n",
    "        return render_template('detail.html', detail=detail)\n",
    "    else:\n",
    "        return render_template('detail.html', detail=None)\n",
    "\n",
    "\n",
    "def get_detail_content(id):\n",
    "    # 使用Elasticsearch查询根据ID获取详细内容\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"ids\": {\n",
    "                \"values\": [id]\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"id\", \"caption\", \"content\"]\n",
    "    }\n",
    "\n",
    "    res = es.search(index='cupdkb_index', body=query)\n",
    "\n",
    "    if res['hits']['total']['value'] > 0:\n",
    "        hit = res['hits']['hits'][0]\n",
    "        source = hit[\"_source\"]\n",
    "        detail = {\n",
    "            \"id\": source[\"id\"],\n",
    "            \"caption\": source[\"caption\"],\n",
    "            \"content\": source[\"content\"]\n",
    "        }\n",
    "        return detail\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=9898)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
